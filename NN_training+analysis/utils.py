import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
import torch
import string
import os
from tqdm import tqdm



def transition_histogram(data, state_extents, state_labels=None, plot=True):
    """ Return a histogram of transitions between states
    TODO: more complex state shapes
    PARAMETERS:
        data : (pd.DataFrame/np.ndarray) with coordinates 
              along which state extents are defined
        state_extents : (np.ndarray) of shape (n_states, dimension, 2)
    """

    n_states = state_extents.shape[0]
    d = state_extents.shape[1]
    assert state_extents.shape[2] == 2, "shape of state extents must be (n_states, dimension, 2)"
    assert len(data.columns) == d, "columns in dataframe must correspond to dimension of state extents"
    if type(data) == pd.DataFrame:
        data = data.values
    if state_labels == None:
        state_labels = string.ascii_uppercase[:n_states]
    
    # assign states
    state_data = np.full(len(data), np.nan)
    for i, state in enumerate(state_extents):
        mask = np.full(len(data), True)
        for j, ext in enumerate(state):
            mask &= (ext[0] <= data[:,j]) & (data[:,j] <= ext[1])
        state_data[mask] = int(i)

    # count transitions
    transitions = np.zeros((n_states, n_states))
    state_data = state_data[~np.isnan(state_data)].astype(int)
    for i in range(len(state_data)-1):
        transitions[state_data[i], state_data[i+1]] += 1

    # total number of transitions between states
    n_total = np.sum(transitions)-np.trace(transitions)
    print("number of total transitions between states: ", n_total)

    if plot:
        _, ax = plt.subplots()
        w = 0.25
        x = np.array([0, w])
        ticks = []
        for i in range(n_states):
            for j in range(i+1, n_states):
                bars = ax.bar(x, [transitions[i,j], transitions[j,i]], w)
                #ax.bar_label(bars, l, padding=3)
                ax.text(x[0],bars[0].get_height(),'$\\rightarrow$', horizontalalignment='center')
                ax.text(x[1],bars[1].get_height(),'$\\leftarrow$', horizontalalignment='center')
                ticks.append('${} \leftrightarrow {}$'.format(state_labels[i], state_labels[j]))
                x += 1
        ax.set_ylabel('count')
        ax.set_title('transitions between states')
        ax.set_xticks(np.arange(x[0])+w/2.)
        ax.set_xticklabels(ticks)

        plt.show()
    return n_total


# ===== PATH UTILS =====

def load_dataframe(path):
    """ Load data from a plumed-format file into a pandas dataframe. """
    # get correct header
    with open('/Volumes/Daten/thesis_data/data/HEADER') as f:
        headers = f.read().splitlines()[1].split(" ")[2:]

    # Load dataframe and use headers for columns names
    try:
        df = pd.read_csv(
            path,
            sep=" ",
            skipinitialspace=True,
            header=None,
            skiprows=1,
            names=headers,
            comment="#",
            index_col=False
        )
    except pd.errors.EmptyDataError:
        df = pd.DataFrame()
    except FileNotFoundError:
        df = pd.DataFrame()
    return df


def convert_colvar(path, dest, write_biasfile=True):
    """ Covert Colvar files from a metaD of paths simulation to Colvars of the actual paths. 
    PARAMETERS
        path : (string) Path to directory containing the MoP colvar files generated by PLUMED
        dest : (string) Path to directory to write converted trajectory files as colvars
        write_biasfile : (boolean) If true, write the bias value for the trajectories to a separate file
    RETURNS
        (pd.DataFrame) Dataframe containing all converted trajectories
    """
    if not os.path.exists(dest):
        os.mkdir(dest)
    
    files = sorted(os.listdir(path), key=lambda x: int(x.split('.')[-1]))
    n_beads = len(files)
    tst_colvar = load_dataframe(path+files[0])
    header = tst_colvar.columns
    n_paths = len(tst_colvar) - 1
    data = np.zeros((n_beads, n_paths, len(header)))
    print('Loading metaD of Paths Colvars...')
    min_l = n_paths
    for i,f in tqdm(enumerate(files), total=len(files)):
        try:
            df = load_dataframe(path+f)
        except Exception:
            print('ERROR: failed to load trajectory', i, f)
        l = len(df) - 1 
        if l < n_paths:
            print('WARING: incomplete trajectory {} of length {} instead of {}'.format(f,l,n_paths))
            if l < min_l:
                min_l = l
        data[i,:l] = df.values[:-1]

    if min_l < n_paths:
        print('WARNING: truncating all data to fit minimum length', min_l)
        data = data[:,:min_l]
    data = data.transpose(1, 0, 2)

    if 'opes.bias' in header and write_biasfile:
        opes = df[['time', 'opes.bias', 'opes.rct']]
        fn = '../' + dest.split('/')[-2] + '_opes.dat'
        opes.to_csv(dest + fn)
    
    print('Writing path Colvars...')
    pddata = []
    for i, traj in tqdm(enumerate(data), total=len(data)):
        colvar = pd.DataFrame(traj, columns=header)
        colvar.to_csv(dest+'path.'+str(i+1), sep=' ')
        colvar['path_id'] = i
        pddata.append(colvar)
    return pd.concat(pddata, ignore_index=True)


def read_paths(path, fnames):
    """ Read converted trajectory colvars.
    PARAMETERS
        path : (string) Path to directory containing trajectory colvars
        fnames : (list[string]) List of files to load (should be sorted)
    RETURNS
        (pd.DataFrame) containing read trajectories
    """
    data = []
    print('Reading paths...')
    for i,fn in tqdm(enumerate(fnames), total=len(fnames)):
        p = path+fn
        if os.path.exists(p):
            # df = utils.load_dataframe(p)
            try:
                df = pd.read_csv(p, delimiter=' ', comment='#', index_col=0)
            except:
                pass # debug point
            df['path_id'] = int(fn.split('.')[-1])
            if not df.empty:
                data.append(df)
    return pd.concat(data, ignore_index=True)


def mic(x, period):
    """ Return periodic images from x for MIC """
    img = [-1,0,1]
    return np.min(np.abs(np.array([x+i*period for i in img])), axis=0)


def calc_average_distance(data, labels, plot_labels = [], kernel_size=1, period=None):
    """ Calculate average adjacent displacement along coordinates specified by labels.
    I.e., a moving average of the oriented displacement between adjacent beads in the individual trajectories.
    Labels should correspond to the column headers in the input data (i.e. 'p.x','p.y','phi','deep.node-0' etc.).
    PARAMETERS
        data : (pd.DataFrame) containing trajectory data
        labels : (list[string]) containing the labels 
        plot_labels : (list[string]) specifying additional columns added to output dataframe for easy plotting
        kernel_size : (integer) moving average kernel size 
    RETURNS 
        (pd.DataFrame) containing columns specified by labels+plot_labels, 
        + additional column 'dist' containing AAD values
    """
    av_diffs = []
    n = int(kernel_size/2)
    # iterate through trajectories
    for _,df in data.groupby('path_id'):
        dist = np.zeros(len(df)-kernel_size)
        vals = []
        for l in labels:
            x = df[l].values
            vals.append(x[n:-n-1])
            dx = mic(x[:-1]-x[1:], period=period[0]) if period is not None else x[:-1]-x[1:]
            av_dx = np.convolve(dx, np.ones(kernel_size)/kernel_size, mode='valid')
            dist += av_dx**2
        dist = np.sqrt(dist)
        vals += [df[l].values[n:-n-1] for l in plot_labels] + [dist]
        df_d = pd.DataFrame({k: v for k, v in zip(labels+plot_labels+['dist'], vals)})
        av_diffs.append(df_d)
    return pd.concat(av_diffs, ignore_index=True)


def calc_path_lengths(data, labels, period=None):
    """ Calculate cumulative adjacent distance along path w.r.t. coordinates specified by labels (path 'length').
    PARAMETERS
        data : (pd.DataFrame) containing trajectory data
        labels : (list[string]) containing the column labels 
    RETURNS
        (list[float]) cumulative length of all paths wrt. labels 
    """
    lens = []
    for i,df in data.groupby('path_id'):
        adj_dist = []
        for j,l in enumerate(labels):
            x = df[l].values
            dx = mic(x[:-1]-x[1:], period=period[j]) if period is not None else x[:-1]-x[1:]
            adj_dist.append(dx)
        if len(adj_dist) == 1:
            length = np.abs(adj_dist[0]).sum()
        else:
            length = np.sqrt(np.array(adj_dist).__pow__(2).sum(0)).sum()
        lens.append([i,length])
    return np.array([np.array(a) for a in lens])


# ===== PLOTTING UTILS =====

def V_mb(x,y):
    """ Evaluate 2D model potential, adapted from Müller&Brown , at points (x,y). """
    A = (-16.0,-11.0,-17.0, 2.0)
    a = (-10.0, -1.0, -6.5, 0.4)
    b = (  5.0,  0.0, 11.0, 0.0)
    c = ( -5.0,-10.0, -6.5, 1.1)
    x0= (  1.0,  0.0, -0.5, 0.0)
    y0= (  1.2,  0.5,  1.5, 1.0)
    offset = -14.12
    v = -offset
    # print explicit analytic form containing potential values
    # s = ''
    for i in range(4):
        v += A[i]*np.exp( a[i]*(x-x0[i])**2 + b[i]*(x-x0[i])*(y-y0[i]) + c[i]*(y-y0[i])**2 )
        # s += '{0:+}*exp({1:+}*(x{4:+})^2{2:+}*(x{4:+})*(y{5:+}){3:+}*(y{5:+})^2)'.format(A[i],a[i],b[i],c[i],-x0[i],-y0[i])
    # print(s)
    return v


def F_mb(x,y):
    """ Evaluate gradient of 2D model potential at point (x,y). """
    A = (-16., -11., -17., 2.0)
    a = (-10.,  -1., -6.5, 0.4)
    b = (  5.,   0.,  11., 0.0)
    c = ( -5., -10., -6.5, 1.1)
    x0= (  1.,   0.0, -0.5, 0.)
    y0= ( 1.2,  0.5,  1.5,  1.)
    f = [0., 0.]
    for i in range(4):
        prefx = A[i] * (2*a[i]*(x-x0[i]) + b[i]*(y-y0[i]))
        prefy = A[i] * (b[i]*(x-x0[i]) + 2*c[i]*(y-y0[i]))
        arg = a[i]*(x-x0[i])**2 + b[i]*(x-x0[i])*(y-y0[i]) + c[i]*(y-y0[i])**2
        f[0] -= prefx * np.exp(arg)
        f[1] -= prefy * np.exp(arg)
    return np.array(f)


def plot_isolines_AlDi(axs):
    # plot isolines of Alanine Dipeptide (reference data) onto axis
    gridx, gridy, fes = np.loadtxt('reference_fes/fes_smooth.dat', skiprows=1, delimiter=' ', unpack=True)
    gridx = gridx.reshape((int(np.sqrt(len(gridx))), -1))
    gridy = gridy.reshape((int(np.sqrt(len(gridy))), -1))
    fes = fes.reshape((int(np.sqrt(len(fes))), -1))

    levels = np.arange(np.min(fes), 70, 6)

    if not isinstance(axs, (list, np.ndarray)):
        axs = [axs]
    for ax in axs:
        ax.contour(gridx, gridy, fes, levels=levels, linewidths=.3, alpha=.5, cmap='Greys_r')


def plot_isolines_MuBr(axs, xlims=(-1.5, 1.5), ylims=(-0., 2.)):
    # plot isolines of Müller-Brown potential onto axis
    nx, ny = (100, 100)
    # xlims=(-2.2, 1.2)#(-1.8, 1.2)
    # ylims=(-0.4, 2.5)#(-0.4, 2.1
    x = np.linspace(xlims[0],xlims[1], nx)
    y = np.linspace(ylims[0],ylims[1], ny)
    xv, yv = np.meshgrid(x, y)

    pot = V_mb(xv,yv)
    max_pot = 35
    pot[pot>max_pot] = np.NaN

    if not isinstance(axs, (list, np.ndarray)):
        axs = [axs]
    if len(axs)==0:
        cnt = plt.contour(xv, yv, pot, 20, cmap='Greys_r', alpha=0.5, linewidths=.5)
    else:
        for ax in axs:
            cnt = ax.contour(xv, yv, pot, 20, cmap='Greys_r', alpha=0.5, linewidths=.5)
    return cnt


def plot_paths(data, xlabel='phi', ylabel='psi', xplabel=None, yplabel=None, title='', clabel='', C=None, ax=None, **kwargs):
    # plot MDoP trajectories as histogram or with given C values
    # additional kwargs are passed to the Axes.hexbin function
    if ax is None:
        _, ax = plt.subplots(1, 1)
    if C is not None:
        if type(C)==str:
            C = data[C].values
        elif len(C) == len(data['path_id'].unique()):
            # one value for each path -> repeat for each point in path
            n = len(data[data['path_id']==data['path_id'].iloc[0]])
            C = np.repeat(C, n)
    ff = ax.hexbin(data[xlabel].values, data[ylabel].values, C=C, **kwargs)
    # colorbar 
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=0.05)
    cbar = plt.colorbar(ff,cax=cax)
    cbar.set_label(clabel, size='x-large')
    ax.set_title(title)
    ax.set_xlabel(xlabel if xplabel is None else xplabel, fontsize='x-large')
    ax.set_ylabel(ylabel if yplabel is None else yplabel, fontsize='x-large')


def plot_isolines_CV(cv,limits=((-3,3),(-3,3)),num_points=(50,50),n_in=2,levels=None,cmap='fessa',axs=None,name=None,cvrange=[-2.5,2.5],make_cbar=True,cvname=None):
    if type(num_points) == int:
        num_points = (num_points,num_points)
    if name is None:
        try:
            name = cv.name_
        except:
            name = ''

    n_out = cv(torch.Tensor(np.zeros((1, n_in)))).size(1)

    # Define grid and evaluate cv on it
    xx = np.linspace(limits[0][0],limits[0][1],num_points[0])
    yy = np.linspace(limits[1][0],limits[1][1],num_points[1])
    xv, yv = np.meshgrid(xx, yy, indexing='xy')
    z = [ np.zeros_like(xv) for _ in range(n_out) ]
    for i in range(num_points[0]):
        for j in range(num_points[1]):
            xy = torch.Tensor([xv[i,j], yv[i,j]])
            for k in range(n_out):
                out = cv(xy)[k]
                out[(out < cvrange[0])|(out > cvrange[1])] = np.NaN
                z[k][i,j] = out

    # Setup plot
    if axs is None:
        _, axs = plt.subplots(figsize=(5,4.*n_out), dpi=100)
        for k,ax in enumerate(axs):
            axs.set_title(f'{cv.name_} {k+1} isolines')

    # Plot countour plot
    for k,ax in enumerate(axs):
        h = ax.contourf(xx, yy, z[k],levels=levels,cmap=cmap)
        if not make_cbar:
            continue
        # colorbar 
        if cvname is None:
            try:
                cvname = f'{cv.name_} {k+1}'
            except:
                cvname = ''
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="5%", pad=0.05)
        cbar = plt.colorbar(h,cax=cax)
        cbar.set_label(cvname, fontsize='large')


def plot_opes(colvar, cvname='deep.node-0', lx='p.x', ly='p.y', title='', iso='mubr'):
    fig,axs = plt.subplots(2, 2, figsize=(10,7), dpi=100)
    fig.suptitle(title)
    axs = axs.flatten()
    # Time evolution (x)
    colvar.plot.scatter('time',lx,c=cvname,s=1,ax=axs[0],cmap='fessa')
    # Time evolution (y)
    colvar.plot.scatter('time',ly,c=cvname,s=1,ax=axs[1],cmap='fessa')
    # Time evolution (cv)
    colvar.plot.scatter('time','opes.bias',c=cvname,s=1,ax=axs[2],cmap='fessa')
    colvar.plot.line('time', 'opes.rct', color='black', alpha=0.7,ax=axs[2])
    # 2D scatter plot
    colvar.plot.scatter(lx,ly,c=cvname,s=1,ax=axs[3],cmap='fessa')
    if iso=='mubr':
        plot_isolines_MuBr(axs[3])
    elif iso=='ala':
        plot_isolines_AlDi(axs[3])
    else:
        raise ValueError("argument iso must be 'mubr' or 'ala'")
    fig.tight_layout()
    return fig, axs